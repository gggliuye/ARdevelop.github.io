---
layout: page_tree_paper
title: Deep Kalman Filter
---


<img src="/assets/img/paperread/chrown0.png" height="25"/> [Deep Kalman Filters Can Filter 2023](https://arxiv.org/abs/2310.19603)

[Structured Inference Networks for Nonlinear State Space Models 2016](https://arxiv.org/abs/1609.09869).
* implementations : [github-structuredinference](https://github.com/clinicalml/structuredinference), [github-dmm](https://github.com/clinicalml/dmm), [github-deepHMM](https://github.com/guxd/deepHMM).

<img src="/assets/img/paperread/chrown.png" height="25"/> [Deep Kalman Filters 2015](https://arxiv.org/abs/1511.05121), in the following kalman filter model, $G_{\alpha}, S_{\beta}, F_{\kappa}$ are assumed to be parameterized by deep neural networks.

$$
\begin{align*}
&z_{1} \sim \mathcal{N} (\mu_{0}; \Sigma_{0}) \\
&z_{t} \sim \mathcal{N} (G_{\alpha}(z_{t-1}, u_{t-1}, \Delta_{t}), S_{\beta}(z_{t-1}, u_{t-1}, \Delta_{t})) \\
&x_{t} \sim \Pi(F_{\kappa}(z_{t}))
\end{align*}
$$

* $\hat{z} = q_{\phi}(z\|x, u)$ for state estimation - kalman filter.
* $\hat{x} = p_{\theta}(x\| \hat{z})$ for pattern reconstruction (denoise).
* <n>This could be used as a base line for large model in image processing.</n>

<img src="/assets/img/paperread/chrown.png" height="25"/> [Stochastic Backpropagation and Approximate Inference in Deep Generative Models 2014](https://arxiv.org/abs/1401.4082). A recognition model to represent an approximate posterior distribution and use this for optimization of a variational lower bound.
